{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7cf5ae5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5fcd2038",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = torch.FloatTensor([[73, 80, 75],\n",
    "                            [93, 88, 93],\n",
    "                            [89, 91, 90],\n",
    "                            [96, 98, 100],\n",
    "                            [73, 66, 70]])\n",
    "y_train = torch.FloatTensor([[152], [185], [180], [196], [142]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7bd83560",
   "metadata": {},
   "outputs": [],
   "source": [
    "W = torch.zeros((3, 1), requires_grad=True) # 입력값이 3개이기 때문에 3 x 1\n",
    "b = torch.zeros(1, requires_grad=True)\n",
    "\n",
    "hypothesis = x_train.matmul(W) + b # 행렬곱을 이용하면 더 빠르고 간단해짐"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bf40f44f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cost = torch.mean((hypothesis - y_train) ** 2) # MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e3d3c569",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD([W, b], lr=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "36dd002c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    0/20 hypothesis: tensor([0., 0., 0., 0., 0.]) Cost: 29661.800781\n",
      "Epoch    1/20 hypothesis: tensor([67.2578, 80.8397, 79.6523, 86.7394, 61.6605]) Cost: 9298.520508\n",
      "Epoch    2/20 hypothesis: tensor([104.9128, 126.0990, 124.2466, 135.3015,  96.1821]) Cost: 2915.712891\n",
      "Epoch    3/20 hypothesis: tensor([125.9942, 151.4381, 149.2133, 162.4896, 115.5097]) Cost: 915.040527\n",
      "Epoch    4/20 hypothesis: tensor([137.7968, 165.6247, 163.1911, 177.7112, 126.3307]) Cost: 287.936005\n",
      "Epoch    5/20 hypothesis: tensor([144.4044, 173.5674, 171.0168, 186.2332, 132.3891]) Cost: 91.371010\n",
      "Epoch    6/20 hypothesis: tensor([148.1035, 178.0144, 175.3980, 191.0042, 135.7812]) Cost: 29.758139\n",
      "Epoch    7/20 hypothesis: tensor([150.1744, 180.5042, 177.8508, 193.6753, 137.6805]) Cost: 10.445305\n",
      "Epoch    8/20 hypothesis: tensor([151.3336, 181.8983, 179.2240, 195.1707, 138.7440]) Cost: 4.391228\n",
      "Epoch    9/20 hypothesis: tensor([151.9824, 182.6789, 179.9928, 196.0079, 139.3396]) Cost: 2.493135\n",
      "Epoch   10/20 hypothesis: tensor([152.3454, 183.1161, 180.4231, 196.4765, 139.6732]) Cost: 1.897688\n",
      "Epoch   11/20 hypothesis: tensor([152.5485, 183.3610, 180.6640, 196.7389, 139.8602]) Cost: 1.710541\n",
      "Epoch   12/20 hypothesis: tensor([152.6620, 183.4982, 180.7988, 196.8857, 139.9651]) Cost: 1.651412\n",
      "Epoch   13/20 hypothesis: tensor([152.7253, 183.5752, 180.8742, 196.9678, 140.0240]) Cost: 1.632387\n",
      "Epoch   14/20 hypothesis: tensor([152.7606, 183.6184, 180.9164, 197.0138, 140.0571]) Cost: 1.625923\n",
      "Epoch   15/20 hypothesis: tensor([152.7802, 183.6427, 180.9399, 197.0395, 140.0759]) Cost: 1.623412\n",
      "Epoch   16/20 hypothesis: tensor([152.7909, 183.6565, 180.9530, 197.0538, 140.0865]) Cost: 1.622141\n",
      "Epoch   17/20 hypothesis: tensor([152.7968, 183.6643, 180.9603, 197.0618, 140.0927]) Cost: 1.621253\n",
      "Epoch   18/20 hypothesis: tensor([152.7999, 183.6688, 180.9644, 197.0662, 140.0963]) Cost: 1.620500\n",
      "Epoch   19/20 hypothesis: tensor([152.8014, 183.6715, 180.9666, 197.0686, 140.0985]) Cost: 1.619770\n",
      "Epoch   20/20 hypothesis: tensor([152.8020, 183.6731, 180.9677, 197.0699, 140.1000]) Cost: 1.619033\n"
     ]
    }
   ],
   "source": [
    "nb_epochs = 20\n",
    "for epoch in range(nb_epochs + 1):\n",
    "    \n",
    "    hypothesis = x_train.matmul(W) + b\n",
    "    \n",
    "    cost = torch.mean((hypothesis - y_train) ** 2)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    print('Epoch {:4d}/{} hypothesis: {} Cost: {:.6f}'.format(\n",
    "        epoch, nb_epochs, hypothesis.squeeze().detach(), cost.item()\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d813fadd",
   "metadata": {},
   "source": [
    "## nn.Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff3a39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "W = torch.zeros((3, 1), requires_grad=True)\n",
    "b = torch.zeros(1, requires_grad=True)\n",
    "\n",
    "hypothesis = x_train.matmul(W) + b\n",
    "'''\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "class MultivariateLinearRegressionModel(nn.Module): # nn.Module 을 상속\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(3, 1) # 입력차원 3, 출력차원 1\n",
    "        \n",
    "    def forward(self, x): # hypothesis 연산 실행\n",
    "        return self.linear(x)\n",
    "\n",
    "# 다음 형식으로 작성하게 될 것\n",
    "model = MultivariateLinearRegressionModel()    \n",
    "hypothesis = model(x_train)\n",
    "\n",
    "# Gradient 계산은 알아서 해줌"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "302f7e32",
   "metadata": {},
   "source": [
    "## F.mse_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "240724d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cost = torch.mean((hypothesis - y_train) ** 2)\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "cost = F.mse_loss(prediction, y_train)\n",
    "# l1_loss, smooth_l1_loss 등등 변경 가능"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68540278",
   "metadata": {},
   "source": [
    "## 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "bb66c2a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = torch.FloatTensor([[73, 80, 75],\n",
    "                            [93, 88, 93],\n",
    "                            [89, 91, 90],\n",
    "                            [96, 98, 100],\n",
    "                            [73, 66, 70]])\n",
    "y_train = torch.FloatTensor([[152], [185], [180], [196], [142]])\n",
    "\n",
    "model = MultivariateLinearRegressionModel()\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-5) # W, b를 적용해줄 필요가 없음. 모델에서 불러오면 됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e9038657",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    0/20 hypothesis: tensor([-14.7836, -17.4342, -17.2559, -19.4419, -12.7692]) Cost: 35614.992188\n",
      "Epoch    1/20 hypothesis: tensor([58.9164, 71.1483, 70.0257, 75.6055, 54.7971]) Cost: 11164.060547\n",
      "Epoch    2/20 hypothesis: tensor([100.1782, 120.7425, 118.8913, 128.8190,  92.6251]) Cost: 3499.993408\n",
      "Epoch    3/20 hypothesis: tensor([123.2790, 148.5086, 146.2494, 158.6112, 113.8037]) Cost: 1097.715210\n",
      "Epoch    4/20 hypothesis: tensor([136.2121, 164.0539, 161.5661, 175.2908, 125.6610]) Cost: 344.727600\n",
      "Epoch    5/20 hypothesis: tensor([143.4527, 172.7572, 170.1413, 184.6291, 132.2996]) Cost: 108.706055\n",
      "Epoch    6/20 hypothesis: tensor([147.5063, 177.6300, 174.9422, 189.8571, 136.0164]) Cost: 34.725765\n",
      "Epoch    7/20 hypothesis: tensor([149.7757, 180.3582, 177.6300, 192.7841, 138.0975]) Cost: 11.536331\n",
      "Epoch    8/20 hypothesis: tensor([151.0461, 181.8857, 179.1348, 194.4228, 139.2628]) Cost: 4.267456\n",
      "Epoch    9/20 hypothesis: tensor([151.7571, 182.7410, 179.9772, 195.3402, 139.9153]) Cost: 1.988766\n",
      "Epoch   10/20 hypothesis: tensor([152.1551, 183.2200, 180.4488, 195.8538, 140.2807]) Cost: 1.274234\n",
      "Epoch   11/20 hypothesis: tensor([152.3777, 183.4882, 180.7128, 196.1413, 140.4855]) Cost: 1.049984\n",
      "Epoch   12/20 hypothesis: tensor([152.5023, 183.6385, 180.8605, 196.3022, 140.6002]) Cost: 0.979413\n",
      "Epoch   13/20 hypothesis: tensor([152.5718, 183.7228, 180.9432, 196.3923, 140.6646]) Cost: 0.957027\n",
      "Epoch   14/20 hypothesis: tensor([152.6106, 183.7700, 180.9894, 196.4427, 140.7008]) Cost: 0.949711\n",
      "Epoch   15/20 hypothesis: tensor([152.6322, 183.7966, 181.0153, 196.4708, 140.7212]) Cost: 0.947134\n",
      "Epoch   16/20 hypothesis: tensor([152.6441, 183.8116, 181.0297, 196.4866, 140.7327]) Cost: 0.946051\n",
      "Epoch   17/20 hypothesis: tensor([152.6507, 183.8201, 181.0377, 196.4954, 140.7393]) Cost: 0.945429\n",
      "Epoch   18/20 hypothesis: tensor([152.6541, 183.8249, 181.0422, 196.5002, 140.7432]) Cost: 0.944945\n",
      "Epoch   19/20 hypothesis: tensor([152.6560, 183.8277, 181.0446, 196.5029, 140.7455]) Cost: 0.944517\n",
      "Epoch   20/20 hypothesis: tensor([152.6568, 183.8294, 181.0460, 196.5044, 140.7469]) Cost: 0.944112\n"
     ]
    }
   ],
   "source": [
    "nb_epochs = 20\n",
    "for epoch in range(nb_epochs + 1):\n",
    "    \n",
    "    hypothesis = model(x_train)\n",
    "    \n",
    "    cost = F.mse_loss(hypothesis, y_train)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    print('Epoch {:4d}/{} hypothesis: {} Cost: {:.6f}'.format(\n",
    "        epoch, nb_epochs, hypothesis.squeeze().detach(), cost.item()\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a9e1ea5",
   "metadata": {},
   "source": [
    "## PyTorch Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9505c3c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        self.x_data = [[73, 80, 75],\n",
    "                      [93, 88, 93],\n",
    "                      [89, 91, 90],\n",
    "                      [96, 98, 100],\n",
    "                      [73, 66, 70]]\n",
    "        self.y_data = [[152], [185], [180], [196], [142]]\n",
    "        \n",
    "    def __len__(self): # 데이터의 수\n",
    "        return len(self.x_data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        x = torch.FloatTensor(self.x_data[idx])\n",
    "        y = torch.FloatTensor(self.y_data[idx])\n",
    "        return x, y\n",
    "    \n",
    "dataset = CustomDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "018d7d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "dataloader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=2, # 미니배치의 크기, 보통 2의 제곱수로 설정\n",
    "    shuffle=True, # epoch 마다 데이터를 섞어서 데이터의 학습 순서를 변경\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d1e6cf92",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    0/20 Batch 1/3 Cost: 14259.089844\n",
      "Epoch    0/20 Batch 2/3 Cost: 10125.019531\n",
      "Epoch    0/20 Batch 3/3 Cost: 2713.448730\n",
      "Epoch    1/20 Batch 1/3 Cost: 478.770691\n",
      "Epoch    1/20 Batch 2/3 Cost: 149.475952\n",
      "Epoch    1/20 Batch 3/3 Cost: 33.458324\n",
      "Epoch    2/20 Batch 1/3 Cost: 52.004570\n",
      "Epoch    2/20 Batch 2/3 Cost: 0.813469\n",
      "Epoch    2/20 Batch 3/3 Cost: 0.624668\n",
      "Epoch    3/20 Batch 1/3 Cost: 16.838942\n",
      "Epoch    3/20 Batch 2/3 Cost: 6.649759\n",
      "Epoch    3/20 Batch 3/3 Cost: 0.704928\n",
      "Epoch    4/20 Batch 1/3 Cost: 1.248612\n",
      "Epoch    4/20 Batch 2/3 Cost: 14.534444\n",
      "Epoch    4/20 Batch 3/3 Cost: 8.932652\n",
      "Epoch    5/20 Batch 1/3 Cost: 12.178062\n",
      "Epoch    5/20 Batch 2/3 Cost: 5.517880\n",
      "Epoch    5/20 Batch 3/3 Cost: 3.394127\n",
      "Epoch    6/20 Batch 1/3 Cost: 2.443189\n",
      "Epoch    6/20 Batch 2/3 Cost: 19.642666\n",
      "Epoch    6/20 Batch 3/3 Cost: 8.231092\n",
      "Epoch    7/20 Batch 1/3 Cost: 12.564452\n",
      "Epoch    7/20 Batch 2/3 Cost: 3.137680\n",
      "Epoch    7/20 Batch 3/3 Cost: 10.592673\n",
      "Epoch    8/20 Batch 1/3 Cost: 8.961987\n",
      "Epoch    8/20 Batch 2/3 Cost: 5.722251\n",
      "Epoch    8/20 Batch 3/3 Cost: 9.866401\n",
      "Epoch    9/20 Batch 1/3 Cost: 0.940808\n",
      "Epoch    9/20 Batch 2/3 Cost: 7.932477\n",
      "Epoch    9/20 Batch 3/3 Cost: 23.108782\n",
      "Epoch   10/20 Batch 1/3 Cost: 8.090649\n",
      "Epoch   10/20 Batch 2/3 Cost: 12.107775\n",
      "Epoch   10/20 Batch 3/3 Cost: 5.290716\n",
      "Epoch   11/20 Batch 1/3 Cost: 3.899523\n",
      "Epoch   11/20 Batch 2/3 Cost: 10.912456\n",
      "Epoch   11/20 Batch 3/3 Cost: 11.799417\n",
      "Epoch   12/20 Batch 1/3 Cost: 5.463030\n",
      "Epoch   12/20 Batch 2/3 Cost: 12.120610\n",
      "Epoch   12/20 Batch 3/3 Cost: 5.323970\n",
      "Epoch   13/20 Batch 1/3 Cost: 2.180603\n",
      "Epoch   13/20 Batch 2/3 Cost: 15.025851\n",
      "Epoch   13/20 Batch 3/3 Cost: 8.256240\n",
      "Epoch   14/20 Batch 1/3 Cost: 10.476453\n",
      "Epoch   14/20 Batch 2/3 Cost: 4.720582\n",
      "Epoch   14/20 Batch 3/3 Cost: 18.324137\n",
      "Epoch   15/20 Batch 1/3 Cost: 4.901329\n",
      "Epoch   15/20 Batch 2/3 Cost: 15.589456\n",
      "Epoch   15/20 Batch 3/3 Cost: 9.246941\n",
      "Epoch   16/20 Batch 1/3 Cost: 0.872671\n",
      "Epoch   16/20 Batch 2/3 Cost: 21.735962\n",
      "Epoch   16/20 Batch 3/3 Cost: 7.166176\n",
      "Epoch   17/20 Batch 1/3 Cost: 11.295594\n",
      "Epoch   17/20 Batch 2/3 Cost: 5.750500\n",
      "Epoch   17/20 Batch 3/3 Cost: 5.027815\n",
      "Epoch   18/20 Batch 1/3 Cost: 1.152907\n",
      "Epoch   18/20 Batch 2/3 Cost: 7.337681\n",
      "Epoch   18/20 Batch 3/3 Cost: 22.559746\n",
      "Epoch   19/20 Batch 1/3 Cost: 10.736591\n",
      "Epoch   19/20 Batch 2/3 Cost: 7.289887\n",
      "Epoch   19/20 Batch 3/3 Cost: 3.155535\n",
      "Epoch   20/20 Batch 1/3 Cost: 14.202239\n",
      "Epoch   20/20 Batch 2/3 Cost: 9.636486\n",
      "Epoch   20/20 Batch 3/3 Cost: 3.504304\n"
     ]
    }
   ],
   "source": [
    "model = MultivariateLinearRegressionModel()\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-5)\n",
    "\n",
    "nb_epochs = 20\n",
    "for epoch in range(nb_epochs + 1):\n",
    "    for batch_idx, samples in enumerate(dataloader):\n",
    "        x_train, y_train = samples\n",
    "        \n",
    "        prediction = model(x_train)\n",
    "        \n",
    "        cost = F.mse_loss(prediction, y_train)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        print('Epoch {:4d}/{} Batch {}/{} Cost: {:.6f}'.format(\n",
    "            epoch, nb_epochs, batch_idx+1, len(dataloader), cost.item()\n",
    "        ))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
